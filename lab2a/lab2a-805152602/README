#NAME: Wenxuan Liu
#EMAIL: allenliux01@163.com
#ID: 805152602

Questions:
2.1.1 - causing conflicts:
	Because when there are small number of iterations, each thread can finish its 'add operations' in the given time slice without being preemptied by other process, so there are no critical session been interrupted. When iterations increases, race condition will occur and cause error when threads are being interrupted by other processes.
	A significantly smaller number of iterations failing seldomly is also because each thread have enough slice time to finish its operation, and seldom race condition will occur to cause error.
2.1.2 - cost of yielding:
	Because "--yield" need to spend time on interrupting the threads and switching to new thread.
	The additional time is going to switch between the threads, which is the overhead of yielding.
	It's not possible to get valid per-operation timings if we are using the --yield option. Because the time of switching threads cannot be measured accurately, so we can only calculate the time by averaging the total time on the number of operations.
2.1.3 - measurement errors:
	The average cost per operation drops with increasing iterations because the overhead is happened when the iterations just begined or about to end (to create and delete stacks and registers etc.). So as the iterations increase, the non-increased overhead is shared by significantly more operations, so the average cost per opersation drops.
	The function of cost per operation based on the number of iterations is exponential according to the plot3. As the iterations increase to significantly large, the cost per operation tends to converge to a stable level, at which the overhead is shared by significantly large amount of iterations. And that cost at significantly large iterations(>100000) is the 'correct' cost.
2.1.4 - costs of serialization:
	Because at low number of threads, the overheads of different synchronizations are all very small, and the major costs are the operations iterations themselves, so different options of synchronizations tends to have similar costs.
	Because as the number of threads rises, the overhead of different synchronizations also increases, given that each thread needs to create, test, or compare lock or data. So the three protected operations slow down.
2.2.1 - scalability of Mutex
	According to lab2_add-5.png, the increase of the time per mutex-protected operation seems to be correlated with the increase of the thread number for add(part-1); However, according to lab2_list-4.png, the time per mutex-protected operation seems NOT correlated with the thread number for list(part-1), since the increase of thread number doesn't affect the cost of the operation.
	The general shape of the curve for 'cost vs thread number' for "add" is going upwards, and the shape of the curve for 'cost vs thread number' for "list" is basically a horizontal line.
	It is because the time between the mutex lock 'locked' and 'unlocked' for "list" is much longer than the one for "add" since there are much more operations done with "list" than with "add". So, the overhead of context switch per operation becomes basically insignificant(too low) for "list", so the increase of thread number doesn't affect the average cost of operation for "list".

2.2.2 - scalability of spin locks
	When the thread number is small(at 1), the cost per operation for "spin-lock" is a little less than the one for "mutex"; When the thread number becomes bigger(2 and more), the cost per operation for "spin-lock" increases and becomes higher than the one for "mutex" which remains basically the same.
	It is because the spin-lock periodically checks each time it is scheduled, and the spinning threads waste significant extra time on the checkings when the thread number increased. However, the mutex only takes overhead time at the moment the critical section is locked and unlocked, which is much smaller than the wasted time of spinning lock. So as the thread number increases, the cost of spin-lock increases while the cost of mutex remains the same.

files:
lab2_add.c:
	A source file that implements a multithreaded program that adds 1 and minuses 1 to a counter.

lab2_list.c:
	A source file that implements a multithreaded program that insert some nodes to a list and delete these nodes from the list.

SortedList.h:
	The header file that defines the interface of an circular linked list.

SortedList.c:
	The source file that defines each function of the linked list described in SortedList.h.

lab2_add.gp:
	The source file that makes the graphs for lab2_add by gnuplot and lab2_add.csv.

lab2_list.gp:
	The source file that makes the graphs for lab2_list by gnuplot and lab2_list.csv.

lab2_add.csv:
	The file that stores the test results of the lab2_add with different testcases in Makefile.

lab2_list.csv:
	The file that stores the test results of the lab2_add with different testcases in Makefile.

README:
	README is the current file which describes all the files and corresponding contents in the tarball.

Makefile:
It has the following 6 functionalities:
	default: 
		compile the lab2_add.c and lab2_list.c to excutable lab2_add and lab2_list with -Wall, -g, -o, -lpthread and -Wextra options.
	build: 
		same as default.
	tests: 
		run the test cases for lab2_add and lab2_list and output to lab2_add.csv and lab2_list.csv
	graphs: 
		make the graphs with gnuplot based on data in lab2_add.csv and lab2_list.csv
	clean: 
		remove all the files created by the makefile, and return the dictionary to the original state as just after untarred.
	dist: 
		make a tarball containing all the required files.
Graphs:
	lab2_add-1.png:
		threads and iterations required to generate a failure (with and without yields)
	lab2_add-2.png:
		average time per operation with and without yields.
	lab2_add-3.png:
		average time per (single threaded) operation vs. the number of iterations.
	lab2_add-4.png:
		threads and iterations that can run successfully with yields under each of the synchronization options.
	lab2_add-5.png:
		average time per (protected) operation vs. the number of threads.
	lab2_list-1.png:
		average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length)
	lab2_list-2.png:
		threads and iterations required to generate a failure (with and without yields).
	lab2_list-3.png:
		iterations that can run (protected) without failure.
	lab2_list-4.png:
		(length-adjusted) cost per operation vs the number of threads for the various synchronization options.

CITATION:
TA's demo codes on the PPT, and the spec of this project:
http://web.cs.ucla.edu/~harryxu/courses/111/winter20/ProjectGuide/P2A.html
